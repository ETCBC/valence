{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "# Verbal valence\n",
    "\n",
    "*Verbal valence* is a kind of signature of a verb, not unlike overloading in programming languages.\n",
    "The meaning of a verb depends on the number and kind of its complements, i.e. the linguistic entities that act as arguments for the semantic function of the verb.\n",
    "\n",
    "We will use a set of flowcharts to specify and compute the sense of a verb in specific contexts depending on the verbal valence. The flowcharts have been composed by Janet Dyk. Although they are not difficult to understand, it takes a good deal of ingenuity to apply them in all the real world situations that we encounter in our corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "[Janet Dyk and Dirk Roorda](https://github.com/ETCBC/valence/wiki/Authors)\n",
    "\n",
    "Last modified 2017-09-13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[References](https://github.com/ETCBC/valence/wiki/References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We carry out the valence project against the Hebrew Text Database of the ETCBC, version 4b.\n",
    "See the description of the [sources](https://github.com/ETCBC/valence/wiki/Sources).\n",
    "\n",
    "We also make use of corrected and enriched data delivered by the\n",
    "[corrEnrich notebook](https://github.com/ETCBC/valence/blob/master/notebooks/corrEnrich.ipynb).\n",
    "The features of that data module are specified\n",
    "[here](https://github.com/ETCBC/valence/wiki/Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We show the results in \n",
    "[SHEBANQ](https://shebanq.ancient-data.org), the website of the ETCBC that exposes its Hebrew Text Database in such a way\n",
    "that users can query it, save their queries, add manual annotations and even upload bulks of generated annotations.\n",
    "That is exactly what we do: the valency results are visible in SHEBANQ in notes view, so that every outcome can be viewed in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flowchart logic\n",
    "\n",
    "Valence flowchart logic translates the verb context into a label that is characteristic for the context.\n",
    "You could say, it is a fingerprint of the context.\n",
    "Verb meanings are complex, depending on context. It turns out that we can organize\n",
    "the meaning selection of verbs around these finger prints.\n",
    "\n",
    "For each verb, the we can specify a *flowchart* as a mapping of fingerprints to concrete meanings.\n",
    "We have flowcharts for a limited, but open set of verbs.\n",
    "They are listed in the\n",
    "[wiki](https://github.com/ETCBC/valence/wiki),\n",
    "and will be referred to from the resulting valence annotations in SHEBANQ.\n",
    "\n",
    "For each verb, the flowchart is represented as a mapping of *sense labels* to meaning templates.\n",
    "A sense label is a code for the presence and nature of direct objects and  complements that are present in the context.\n",
    "See the [legend](https://github.com/ETCBC/valence/wiki/Legend) of sense labels.\n",
    "\n",
    "The interesting part is the *sense template*, \n",
    "which consist of a translation text augmented with placeholders for the direct objecs and complements.\n",
    "\n",
    "See for example the flowchart of [NTN](https://github.com/ETCBC/valence/wiki/FC_NTN).\n",
    "\n",
    "* `{verb}` the verb occurrence in question\n",
    "* `{pdos}` principal direct objects (phrase)\n",
    "* `{kdos}` K-objects (phrase)\n",
    "* `{ldos}` L-objects (phrase)\n",
    "* `{ndos}` direct objects (phrase) (none of the above)\n",
    "* `{idos}` infinitive construct (clause) objects\n",
    "* `{cdos}` direct objects (clause) (none of the above)\n",
    "* `{inds}` indirect objects\n",
    "* `{bens}` benefactive adjuncts\n",
    "* `{locs}` locatives\n",
    "* `{cpls}` complements, not marked as either indirect object or locative\n",
    "\n",
    "In case there are multiple entities, the algorithm returns them chunked as phrases/clauses.\n",
    "\n",
    "Apart from the template, there is also a *status* and an optional *account*. \n",
    "\n",
    "The status is ``!`` in normal cases, ``?`` in dubious cases, and ``-`` in erroneous cases.\n",
    "In SHEBANQ these statuses are translated into colors of the notes (blue/orange/red).\n",
    "\n",
    "The account contains information about the grounds of which the algorithm has arrived at its conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "senses = set('''\n",
    "<FH\n",
    "BR>\n",
    "CJT\n",
    "DBQ\n",
    "FJM\n",
    "NTN\n",
    "QR>\n",
    "ZQN\n",
    "'''.strip().split())\n",
    "\n",
    "senseLabels = '''\n",
    "--\n",
    "-i\n",
    "-b\n",
    "-p\n",
    "-c\n",
    "d-\n",
    "di\n",
    "db\n",
    "dp\n",
    "dc\n",
    "n.\n",
    "l.\n",
    "k.\n",
    "i.\n",
    "c.\n",
    "'''.strip().split()\n",
    "\n",
    "constKindSpecs = '''\n",
    "verb:verb\n",
    "dos:direct object\n",
    "pdos:principal direct object\n",
    "kdos:K-object\n",
    "ldos:L-object\n",
    "ndos:NP-object\n",
    "idos:infinitive object clause\n",
    "cdos:direct object clause\n",
    "inds:indirect object\n",
    "bens:benefactive\n",
    "locs:locative\n",
    "cpls:complement\n",
    "'''.strip().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "See the results as annotations on [SHEBANQ](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxlbmNl&tp=txt_tb1&nget=v).\n",
    "\n",
    "The complete set of results is in the note set \n",
    "[valence](https://shebanq.ancient-data.org/hebrew/note?version=4b&id=Mnx2YWxlbmNl&tp=txt_tb1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firing up the engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = 'etcbc'\n",
    "version = '4b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.3.10\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "120 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "ETCBC = f'hebrew/{source}{version}'\n",
    "VALENCE = f'tf/{version}'\n",
    "TF = Fabric(locations=['~/github/text-fabric-data-legacy', '~/github/valence'], modules=[ETCBC, VALENCE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.02s B book                 from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.01s B chapter              from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.01s B verse                from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.21s B g_word_utf8          from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.10s B trailer_utf8         from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.12s B function             from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.23s B rela                 from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.26s B typ                  from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.17s B lex                  from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.18s B prs                  from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.17s B uvf                  from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.18s B sp                   from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.18s B pdp                  from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.17s B ls                   from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.17s B vs                   from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.17s B vt                   from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.11s B nametype             from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.20s B gloss                from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.03s B label                from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.32s B number               from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.04s B s_manual             from /Users/dirk/github/valence/tf/4b\n",
      "   |     0.05s B f_correction         from /Users/dirk/github/valence/tf/4b\n",
      "   |     0.10s B valence              from /Users/dirk/github/valence/tf/4b\n",
      "   |     0.12s B predication          from /Users/dirk/github/valence/tf/4b\n",
      "   |     0.09s B grammatical          from /Users/dirk/github/valence/tf/4b\n",
      "   |     0.06s B original             from /Users/dirk/github/valence/tf/4b\n",
      "   |     0.07s B lexical              from /Users/dirk/github/valence/tf/4b\n",
      "   |     0.07s B semantic             from /Users/dirk/github/valence/tf/4b\n",
      "   |     0.66s B mother               from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.00s Feature overview: 114 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "  8.85s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    function rela typ\n",
    "    g_word_utf8 trailer_utf8\n",
    "    lex prs uvf sp pdp ls vs vt nametype gloss\n",
    "    book chapter verse label number\n",
    "    s_manual f_correction\n",
    "    valence predication grammatical original lexical semantic\n",
    "    mother\n",
    "''')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "home_dir = os.path.expanduser('~').replace('\\\\', '/')\n",
    "base_dir = '{}/github/valence'.format(home_dir)\n",
    "result_dir = '{}/annotations'.format(base_dir)\n",
    "flowchartBase = 'https://github.com/ETCBC/valence/wiki'\n",
    "\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators\n",
    "\n",
    "Here we specify by what features we recognize key constituents.\n",
    "We use predominantly features that come from the correction/enrichment workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pf ... : predication feature\n",
    "# gf_... : grammatical feature\n",
    "# vf_... : valence feature\n",
    "# sf_... : lexical feature\n",
    "# of_... : original feature\n",
    "\n",
    "pf_predicate = {\n",
    "    'regular',\n",
    "}\n",
    "gf_direct_object = {\n",
    "    'principal_direct_object',\n",
    "    'NP_direct_object',\n",
    "    'direct_object',\n",
    "    'L_object',\n",
    "    'K_object',\n",
    "    'infinitive_object',\n",
    "}\n",
    "gf_indirect_object = {\n",
    "    'indirect_object',\n",
    "}\n",
    "gf_complement = {\n",
    "    '*',\n",
    "}\n",
    "sf_locative = {\n",
    "    'location',\n",
    "}\n",
    "sf_benefactive ={\n",
    "    'benefactive',\n",
    "}\n",
    "vf_locative = {\n",
    "    'complement',\n",
    "    'adjunct',\n",
    "}\n",
    "\n",
    "verbal_stems = set('''\n",
    "    qal\n",
    "'''.strip().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronominal suffixes\n",
    "We collect the information to determine how to render pronominal suffixes on words. \n",
    "On verbs, they must be rendered *accusatively*, like `see him`.\n",
    "But on nouns, they must be rendered *genitively*, like `hand my`.\n",
    "So we make an inventory of part of speech types and the pronominal suffixes that occur on them.\n",
    "On that basis we make the translation dictionaries `pronominal suffix` and `switch_prs`.\n",
    "\n",
    "Finally, we define a function `get_prs_info` that for each word delivers the pronominal suffix info and gloss,\n",
    "if there is any, and else `(None, None)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjv  H   :    16\n",
      "adjv  HM  :    10\n",
      "adjv  J   :    25\n",
      "adjv  K   :    35\n",
      "adjv  K=  :     3\n",
      "adjv  KM  :     7\n",
      "adjv  M   :     8\n",
      "adjv  MW  :     1\n",
      "adjv  NW  :     5\n",
      "adjv  W   :    59\n",
      "adjv  absent :  9323\n",
      "advb  n/a :  4550\n",
      "art   n/a : 30380\n",
      "conj  n/a : 62723\n",
      "inrg  K   :     1\n",
      "inrg  M   :     2\n",
      "inrg  W   :     5\n",
      "inrg  absent :  1277\n",
      "intj  K   :    13\n",
      "intj  K=  :     7\n",
      "intj  KM  :     2\n",
      "intj  M   :    37\n",
      "intj  NJ  :   181\n",
      "intj  NW  :     8\n",
      "intj  W   :     3\n",
      "intj  absent :  1634\n",
      "nega  n/a :  6053\n",
      "nmpr  n/a : 33083\n",
      "prde  n/a :  2660\n",
      "prep  H   :  1019\n",
      "prep  H=  :    36\n",
      "prep  HJ  :    13\n",
      "prep  HM  :  1499\n",
      "prep  HN  :    74\n",
      "prep  HW  :   174\n",
      "prep  HWN :    19\n",
      "prep  J   :  1853\n",
      "prep  K   :  1634\n",
      "prep  K=  :   353\n",
      "prep  KM  :  1181\n",
      "prep  KN  :     2\n",
      "prep  KWN :     1\n",
      "prep  M   :   684\n",
      "prep  MW  :    68\n",
      "prep  N   :     3\n",
      "prep  N>  :     4\n",
      "prep  NJ  :   105\n",
      "prep  NW  :   539\n",
      "prep  W   :  3247\n",
      "prep  absent : 60765\n",
      "prin  n/a :  1021\n",
      "prps  n/a :  5011\n",
      "subs  H   :  1633\n",
      "subs  H=  :   108\n",
      "subs  HJ  :    58\n",
      "subs  HM  :  1417\n",
      "subs  HN  :   114\n",
      "subs  HW  :   340\n",
      "subs  HWN :    32\n",
      "subs  J   :  4332\n",
      "subs  K   :  4362\n",
      "subs  K=  :   744\n",
      "subs  KM  :  1335\n",
      "subs  KN  :    16\n",
      "subs  KWN :     7\n",
      "subs  M   :  1919\n",
      "subs  MW  :    25\n",
      "subs  N   :    29\n",
      "subs  N>  :     3\n",
      "subs  NJ  :    19\n",
      "subs  NW  :   809\n",
      "subs  W   :  7653\n",
      "subs  absent : 96518\n",
      "verb  H   :   682\n",
      "verb  H=  :    17\n",
      "verb  HJ  :     6\n",
      "verb  HM  :   121\n",
      "verb  HN  :     4\n",
      "verb  HW  :  1097\n",
      "verb  J   :   356\n",
      "verb  K   :  1089\n",
      "verb  K=  :   201\n",
      "verb  KM  :   132\n",
      "verb  KN  :     1\n",
      "verb  KWN :     2\n",
      "verb  M   :  1288\n",
      "verb  MW  :    23\n",
      "verb  N   :    15\n",
      "verb  N>  :     3\n",
      "verb  NJ  :  1016\n",
      "verb  NW  :   274\n",
      "verb  W   :   938\n",
      "verb  absent : 66414\n"
     ]
    }
   ],
   "source": [
    "prss = collections.defaultdict(lambda: collections.defaultdict(lambda: 0))\n",
    "for w in F.otype.s('word'):\n",
    "    prss[F.sp.v(w)][F.prs.v(w)] += 1\n",
    "for sp in sorted(prss):\n",
    "    for prs in sorted(prss[sp]):\n",
    "        print('{:<5} {:<3} : {:>5}'.format(sp, prs, prss[sp][prs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pronominal_suffix = {\n",
    "    'accusative': {\n",
    "        'W': ('p3-sg-m', 'him'),\n",
    "        'K': ('p2-sg-m', 'you:m'),\n",
    "        'J': ('p1-sg-', 'me'),\n",
    "        'M': ('p3-pl-m', 'them:mm'),\n",
    "        'H': ('p3-sg-f', 'her'),\n",
    "        'HM': ('p3-pl-m', 'them:mm'),\n",
    "        'KM': ('p2-pl-m', 'you:mm'),\n",
    "        'NW': ('p1-pl-', 'us'),\n",
    "        'HW': ('p3-sg-m', 'him'),\n",
    "        'NJ': ('p1-sg-', 'me'),\n",
    "        'K=': ('p2-sg-f', 'you:f'),\n",
    "        'HN': ('p3-pl-f', 'them:ff'),\n",
    "        'MW': ('p3-pl-m', 'them:mm'),\n",
    "        'N': ('p3-pl-f', 'them:ff'),\n",
    "        'KN': ('p2-pl-f', 'you:ff'),\n",
    "    },\n",
    "    'genitive' : {\n",
    "        'W': ('p3-sg-m', 'his'),\n",
    "        'K': ('p2-sg-m', 'your:m'),\n",
    "        'J': ('p1-sg-', 'my'),\n",
    "        'M': ('p3-pl-m', 'their:mm'),\n",
    "        'H': ('p3-sg-f', 'her'),\n",
    "        'HM': ('p3-pl-m', 'their:mm'),\n",
    "        'KM': ('p2-pl-m', 'your:mm'),\n",
    "        'NW': ('p1-pl-', 'our'),\n",
    "        'HW': ('p3-sg-m', 'his'),\n",
    "        'NJ': ('p1-sg-', 'my'),\n",
    "        'K=': ('p2-sg-f', 'your:f'),\n",
    "        'HN': ('p3-pl-f', 'their:ff'),\n",
    "        'MW': ('p3-pl-m', 'their:mm'),\n",
    "        'N': ('p3-pl-f', 'their:ff'),\n",
    "        'KN': ('p2-pl-f', 'your:ff'),        \n",
    "    }\n",
    "}\n",
    "switch_prs = dict(\n",
    "    subs = 'genitive',\n",
    "    verb = 'accusative',\n",
    "    prep = 'accusative',\n",
    "    conj = None,\n",
    "    nmpr = None,\n",
    "    art = None,\n",
    "    adjv = 'genitive',\n",
    "    nega = None,\n",
    "    prps = None,\n",
    "    advb = None,\n",
    "    prde = None,\n",
    "    intj = 'accusative',\n",
    "    inrg = 'genitive',\n",
    "    prin = None,\n",
    ")\n",
    "\n",
    "def get_prs_info(w):\n",
    "    sp = F.sp.v(w)\n",
    "    prs = F.prs.v(w)\n",
    "    switch = switch_prs[sp]\n",
    "    return pronominal_suffix.get(switch, {}).get(prs, (None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a verb-clause index\n",
    "\n",
    "We generate an index which gives for each verb lexeme a list of clauses that have that lexeme as the main verb.\n",
    "In the index we store the clause node together with the word node(s) that carries the main verb(s).\n",
    "\n",
    "Clauses may have multiple verbs. In many cases it is a copula plus an other verb.\n",
    "In those cases, we are interested in the other verb, so we exclude copulas.\n",
    "\n",
    "Yet, there are also sentences with more than one main verb.\n",
    "In those cases, we treat both verbs separately as main verb of one and the same clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    17s Making the verb-clause index\n",
      "    19s Done (68975 clauses)\n"
     ]
    }
   ],
   "source": [
    "info('Making the verb-clause index')\n",
    "occs = collections.defaultdict(list)   # dictionary of all verb occurrence nodes per verb lexeme\n",
    "verb_clause = collections.defaultdict(list)    # dictionary of all verb occurrence nodes per clause node\n",
    "clause_verb = collections.OrderedDict() # idem but for the occurrences of selected verbs\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    if F.sp.v(w) != 'verb': continue\n",
    "    lex = F.lex.v(w).rstrip('[')\n",
    "    pf = F.predication.v(L.u(w, 'phrase')[0])\n",
    "    if pf in pf_predicate:\n",
    "        cn = L.u(w, 'clause')[0]\n",
    "        clause_verb.setdefault(cn, []).append(w)\n",
    "        verb_clause[lex].append((cn, w))\n",
    "info('Done ({} clauses)'.format(len(clause_verb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Indirect) Objects, Locatives, Benefactives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    21s Finding key constituents\n",
      "    27s Done, 47278 clauses with relevant constituents\n"
     ]
    }
   ],
   "source": [
    "info('Finding key constituents')\n",
    "constituents = collections.defaultdict(lambda: collections.defaultdict(set))\n",
    "ckinds = '''\n",
    "    dos pdos ndos kdos ldos idos cdos inds locs cpls bens\n",
    "'''.strip().split()\n",
    "\n",
    "# go through all relevant clauses and collect all types of direct objects\n",
    "for c in clause_verb:\n",
    "    these_constituents = collections.defaultdict(set)\n",
    "    # phrase like constituents\n",
    "    for p in L.d(c, 'phrase'):\n",
    "        gf = F.grammatical.v(p)\n",
    "        of = F.original.v(p)\n",
    "        sf = F.semantic.v(p)\n",
    "        vf = F.valence.v(p)\n",
    "        ckind = None\n",
    "        if gf in gf_direct_object:\n",
    "            if gf =='principal_direct_object':\n",
    "                ckind = 'pdos'\n",
    "            elif gf == 'NP_direct_object':\n",
    "                ckind = 'ndos'\n",
    "            elif gf == 'L_object':\n",
    "                ckind = 'ldos'\n",
    "            elif gf == 'K_object':\n",
    "                ckind = 'kdos'\n",
    "            else:\n",
    "                ckind = 'dos'\n",
    "        elif gf in gf_indirect_object:\n",
    "            ckind = 'inds'\n",
    "        elif  sf and sf in sf_benefactive:\n",
    "            ckind = 'bens'\n",
    "        elif sf in sf_locative and vf in vf_locative:\n",
    "            ckind = 'locs'\n",
    "        elif gf in gf_complement:\n",
    "            ckind = 'cpls'\n",
    "        if ckind: these_constituents[ckind].add(p)\n",
    "\n",
    "    # clause like constituents: only look for object clauses dependent on this clause\n",
    "    for ac in L.d(L.u(c, 'sentence')[0], 'clause'):\n",
    "        dep = list(E.mother.f(ac))\n",
    "        if len(dep) and dep[0] == c:\n",
    "            gf = F.grammatical.v(ac)\n",
    "            ckind = None\n",
    "            if gf in gf_direct_object:\n",
    "                if gf == 'direct_object':\n",
    "                    ckind = 'cdos'\n",
    "                elif gf == 'infinitive_object':\n",
    "                    ckind = 'idos'\n",
    "            if ckind: these_constituents[ckind].add(ac)\n",
    "    \n",
    "    for ckind in these_constituents:\n",
    "        constituents[c][ckind] |= these_constituents[ckind]\n",
    "\n",
    "info('Done, {} clauses with relevant constituents'.format(len(constituents))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE 430372=clause (Cmpl-InfC)\n",
      "CLAUSE: L <FWT H DBR H ZH \n",
      "VERSE\n",
      "Genesis 34:14 W J>MRW >LJHM L> NWKL L <FWT H DBR H ZH L TT >T >XTNW L >JC >CR LW <RLH KJ XRPH HW> LNW \n",
      "GLOSS and say to not be able to make the word the this to give <object marker> sister to man <relative> to foreskin that reproach she to\n",
      "\n",
      "PHRASES\n",
      "\n",
      "616668 (Pred-InfC) L <FWT  \"to make\"\n",
      "valence = core; grammatical = NA; lexical = ; semantic = \n",
      "\n",
      "616669 (Objc-InfC) H DBR H ZH  \"the word the this\"\n",
      "valence = complement; grammatical = principal_direct_object; lexical = ; semantic = \n",
      "\n",
      "SUBCLAUSES\n",
      "\n",
      "430373 (Adju-InfC) L TT >T >XTNW L >JC  \"to give <object marker> sister to man\"\n",
      "valence = NA; grammatical = infinitive_object; lexical = ; semantic = \n",
      "\n",
      "CONSTITUENTS\n",
      "dos : \n",
      "pdos: 616669\n",
      "ndos: \n",
      "kdos: \n",
      "ldos: \n",
      "idos: 430373\n",
      "cdos: \n",
      "inds: \n",
      "locs: \n",
      "cpls: \n",
      "bens: \n",
      "================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testcases = (\n",
    "#    426955,\n",
    "#    427654,\n",
    "#    428420,\n",
    "#    429412,\n",
    "#    429501,\n",
    "#    429862,\n",
    "#    431695,\n",
    "#    431893,\n",
    "    430372,\n",
    ")\n",
    "\n",
    "def showcase(n):\n",
    "    otype = F.otype.v(n)\n",
    "    verseNode = L.u(n, 'verse')[0]\n",
    "    place = T.sectionFromNode(verseNode)\n",
    "    print('''CASE {}={} ({}-{})\\nCLAUSE: {}\\nVERSE\\n{} {}\\nGLOSS {}\\n'''.format(\n",
    "        n, otype, F.rela.v(n), F.typ.v(n),\n",
    "        T.text(L.d(n, 'word'), fmt='text-trans-plain'),\n",
    "        '{} {}:{}'.format(*place),\n",
    "        T.text(L.d(verseNode, 'word'), fmt='text-trans-plain'),\n",
    "        ' '.join(F.gloss.v(w) for w in L.d(verseNode, 'word'))\n",
    "    ))\n",
    "    print('PHRASES\\n')\n",
    "    for p in L.d(n, 'phrase'):\n",
    "        print('''{} ({}-{}) {} \"{}\"'''.format(\n",
    "            p, F.function.v(p), F.typ.v(n),\n",
    "            T.text(L.d(p, 'word'), fmt='text-trans-plain'),\n",
    "            ' '.join(F.gloss.v(w) for w in L.d(p, 'word')),\n",
    "        ))\n",
    "        print('valence = {}; grammatical = {}; lexical = {}; semantic = {}\\n'.format(\n",
    "            F.valence.v(p),\n",
    "            F.grammatical.v(p),\n",
    "            F.lexical.v(p),\n",
    "            F.semantic.v(p),\n",
    "        ))\n",
    "    print('SUBCLAUSES\\n')\n",
    "    for ac in L.d(L.u(n, 'sentence')[0], 'clause'):\n",
    "        dep = list(E.mother.f(ac))\n",
    "        if not(len(dep) and dep[0] == n): continue\n",
    "        print('''{} ({}-{}) {} \"{}\"'''.format(\n",
    "            ac, F.rela.v(ac), F.typ.v(ac),\n",
    "            T.text(L.d(ac, 'word'), fmt='text-trans-plain'),\n",
    "            ' '.join(F.gloss.v(w) for w in L.d(ac, 'word')),\n",
    "        ))\n",
    "        print('valence = {}; grammatical = {}; lexical = {}; semantic = {}\\n'.format(\n",
    "            F.valence.v(ac),\n",
    "            F.grammatical.v(ac),\n",
    "            F.lexical.v(ac),\n",
    "            F.semantic.v(ac),\n",
    "        ))\n",
    "\n",
    "    print('CONSTITUENTS')\n",
    "    for ckind in ckinds:\n",
    "        print('{:<4}: {}'.format(ckind, ','.join(str(x) for x in sorted(constituents[n][ckind]))))\n",
    "    print('================\\n')\n",
    "\n",
    "for n in (testcases): showcase(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22175 clauses with  1 dos        constituents\n",
      "25103 clauses with  0 dos        constituents\n",
      "22175 clauses with  a dos        constituent\n",
      " 3440 clauses with  1 pdos       constituents\n",
      "43838 clauses with  0 pdos       constituents\n",
      " 3440 clauses with  a pdos       constituent\n",
      "  963 clauses with  1 ndos       constituents\n",
      "46315 clauses with  0 ndos       constituents\n",
      "  963 clauses with  a ndos       constituent\n",
      "  105 clauses with  1 kdos       constituents\n",
      "47173 clauses with  0 kdos       constituents\n",
      "  105 clauses with  a kdos       constituent\n",
      "   29 clauses with  2 ldos       constituents\n",
      " 3656 clauses with  1 ldos       constituents\n",
      "43593 clauses with  0 ldos       constituents\n",
      " 3685 clauses with  a ldos       constituent\n",
      "    1 clauses with  3 idos       constituents\n",
      "   18 clauses with  2 idos       constituents\n",
      " 1167 clauses with  1 idos       constituents\n",
      "46092 clauses with  0 idos       constituents\n",
      " 1186 clauses with  a idos       constituent\n",
      "   12 clauses with  2 cdos       constituents\n",
      " 1365 clauses with  1 cdos       constituents\n",
      "45901 clauses with  0 cdos       constituents\n",
      " 1377 clauses with  a cdos       constituent\n",
      "   59 clauses with  2 inds       constituents\n",
      " 6174 clauses with  1 inds       constituents\n",
      "41045 clauses with  0 inds       constituents\n",
      " 6233 clauses with  a inds       constituent\n",
      "    1 clauses with  6 locs       constituents\n",
      "   22 clauses with  3 locs       constituents\n",
      "  371 clauses with  2 locs       constituents\n",
      "12574 clauses with  1 locs       constituents\n",
      "34310 clauses with  0 locs       constituents\n",
      "12968 clauses with  a locs       constituent\n",
      "   43 clauses with  2 cpls       constituents\n",
      " 7262 clauses with  1 cpls       constituents\n",
      "39973 clauses with  0 cpls       constituents\n",
      " 7305 clauses with  a cpls       constituent\n",
      "    2 clauses with  2 bens       constituents\n",
      "  173 clauses with  1 bens       constituents\n",
      "47103 clauses with  0 bens       constituents\n",
      "  175 clauses with  a bens       constituent\n",
      "68975 clauses\n"
     ]
    }
   ],
   "source": [
    "# Counting constituents\n",
    "\n",
    "constituents_count = collections.defaultdict(collections.Counter)\n",
    "\n",
    "for c in constituents:\n",
    "    for ckind in ckinds:\n",
    "        n = len(constituents[c][ckind])\n",
    "        constituents_count[ckind][n] += 1\n",
    "\n",
    "for ckind in ckinds:\n",
    "    total = 0\n",
    "    for (count, n) in sorted(constituents_count[ckind].items(), key=lambda y: -y[0]):\n",
    "        if count: total += n\n",
    "        info('{:>5} clauses with {:>2} {:<10} constituents'.format(n, count, ckind), tm=False)\n",
    "    info('{:>5} clauses with {:>2} {:<10} constituent'.format(total, 'a', ckind), tm=False)\n",
    "info('{:>5} clauses'.format(len(clause_verb)), tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Applying the flowchart\n",
    "\n",
    "We can now apply the flowchart in a straightforward manner.\n",
    "\n",
    "We output the results as a comma separated file that can be imported directly into SHEBANQ as a set of notes, so that the reader can check results within SHEBANQ. This has the benefit that the full context is available, and also data view can be called up easily to inspect the coding situation for each particular instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gloss_hacks = {\n",
    "    'XQ/': 'law/precept',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reptext(label, ckind, v, phrases, num=False, txt=False, gloss=False, textformat='text-trans-plain'): \n",
    "    if phrases == None: return ''\n",
    "    label_rep = '{}='.format(label) if label else ''\n",
    "    phrases_rep = []\n",
    "    for p in sorted(phrases, key=sortKey):\n",
    "        ptext = '[{}|'.format(F.number.v(p) if num else '[')\n",
    "        if txt:\n",
    "            ptext += T.text(L.d(p, 'word'), fmt=textformat)\n",
    "        if gloss:\n",
    "            words = L.d(p, 'word')\n",
    "            if ckind == 'ldos' and F.lex.v(words[0]) == 'L': words = words[1:]\n",
    "\n",
    "            wtexts = []\n",
    "            for w in words:\n",
    "                g = gloss_hacks.get(F.lex.v(w), F.gloss.v(w)).replace('<object marker>','&')\n",
    "                if F.lex.v(w) == 'BJN/' and F.pdp.v(w) == 'prep': g = 'between'\n",
    "                prs_g = get_prs_info(w)[1]\n",
    "                uvf = F.uvf.v(w)\n",
    "                wtext = ''\n",
    "                if uvf == 'H': ptext += 'toward '\n",
    "                wtext += g if w != v else '' # we do not have to put in the gloss of the verb in question\n",
    "                wtext += ('~'+prs_g) if prs_g != None else ''\n",
    "                wtexts.append(wtext)\n",
    "            ptext += ' '.join(wtexts)\n",
    "        ptext += ']'\n",
    "        phrases_rep.append(ptext)\n",
    "    return ' '.join(phrases_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debug_messages = collections.defaultdict(lambda: collections.defaultdict(list))\n",
    "\n",
    "constKinds = collections.OrderedDict()\n",
    "\n",
    "for constKindSpec in constKindSpecs:\n",
    "    (constKind, constKindName) = constKindSpec.strip().split(':', 1)\n",
    "    constKinds[constKind] = constKindName\n",
    "\n",
    "def flowchart(v, lex, verb, consts):\n",
    "    consts = deepcopy(consts)\n",
    "    n_ = collections.defaultdict(lambda: 0)\n",
    "    for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "    char1 = None\n",
    "    char2 = None\n",
    "    # determine char 1 of the sense label\n",
    "    if n_['pdos'] > 0:\n",
    "        if n_['ndos'] > 0: char1 = 'n'\n",
    "        elif n_['cdos'] > 0: char1 = 'c'\n",
    "        elif n_['ldos'] > 0: char1 = 'l'\n",
    "        elif n_['kdos'] > 0: char1 = 'k'\n",
    "        elif n_['idos'] > 0: char1 = 'i'\n",
    "        else:\n",
    "        # in trouble: if there is a principal direct object, there should be an other object as well\n",
    "        # and the other one should be an NP, object clause, L_object, K_object, or I_object\n",
    "        # If this happens, it is probably the result of manual correction\n",
    "        # We warn, and remedy\n",
    "            msg_rep = '; '.join('{} {}'.format(n_[ckind], ckind) for ckind in ckinds)\n",
    "            if n_['dos'] > 0:\n",
    "                # there is an other object (dos should only be used if there is a single object)\n",
    "                # we'll put the dos in the ndos (which was empty)\n",
    "                # This could be caused by a manual enrichment sheet that has been generated \n",
    "                # before the concept of NP_direct_object had been introduced\n",
    "                char1 = 'n'\n",
    "                consts['ndos'] = consts['dos']\n",
    "                del consts['dos']\n",
    "                debug_messages[lex]['pdos with dos'].append('{}: {}'.format(T.sectionFromNode(v), msg_rep))\n",
    "            else:\n",
    "                # there is not another object, we treat this as a single object, so as a dos\n",
    "                char1 = 'd'\n",
    "                consts['dos'] = consts['pdos']\n",
    "                del consts['pdos']\n",
    "                debug_messages[lex]['lonely pdos'].append('{}: {}'.format(T.sectionFromNode(v), msg_rep))\n",
    "    else:\n",
    "        if n_['cdos'] > 0:\n",
    "        # in the case of a single object, the clause objects act as ordinary objects\n",
    "            char1 = 'd'\n",
    "            consts['dos'] |= consts['cdos']\n",
    "            del consts['cdos']\n",
    "        if n_['ndos'] > 0:\n",
    "        # in the case of a single object, the np_objects act as ordinary objects\n",
    "            char1 = 'd'\n",
    "            consts['dos'] |= consts['ndos']\n",
    "            del consts['ndos']\n",
    "\n",
    "    n_ = collections.defaultdict(lambda: 0)\n",
    "    for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "\n",
    "    if n_['pdos'] == 0 and n_['dos'] > 0:\n",
    "        char1 = 'd'\n",
    "    if n_['pdos'] == 0 and n_['dos'] == 0:\n",
    "        char1 = '-'\n",
    "\n",
    "    # determine char 2 of the sense label\n",
    "    if char1 in 'nclki':\n",
    "        char2 = '.'\n",
    "    else:\n",
    "        if n_['inds'] > 0:\n",
    "            char2 = 'i'\n",
    "        elif n_['bens'] > 0:\n",
    "            char2 = 'b'\n",
    "        elif n_['locs'] > 0:\n",
    "            char2 = 'p'\n",
    "        elif n_['cpls'] > 0:\n",
    "            char2 = 'c'\n",
    "        else:\n",
    "            char2 = '-'\n",
    "\n",
    "    sense_label = char1+char2\n",
    "    sense = lex if lex in senses else None\n",
    "    status = '*' if lex in senses else '?'\n",
    "    \n",
    "    verb_rep = reptext('', '', v, verb, num=True, gloss=True)\n",
    "    consts_rep = dict((ckind, reptext('', ckind, v, consts[ckind], num=True, gloss=True)) for ckind in consts)\n",
    "        \n",
    "    return (sense_label, sense, status, consts_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sfields = '''\n",
    "    version\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    clause_atom\n",
    "    is_shared\n",
    "    is_published\n",
    "    status\n",
    "    keywords\n",
    "    ntext\n",
    "'''.strip().split()\n",
    "\n",
    "sfields_fmt = ('{}\\t' * (len(sfields) - 1)) + '{}\\n' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the flowchart\n",
    "\n",
    "The next cell finally performs all the flowchart computations for all verbs in all contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    43s Checking the flowcharts\n",
      "    43s No flowchart for 1540 verbs, e.g. <BC, <BD, <BH, <BR, <BR=, <BT, <BV, <BV=, <CC, <CN\n",
      "    43s All flowcharts belong to a verb in the corpus\n"
     ]
    }
   ],
   "source": [
    "info('Checking the flowcharts')\n",
    "missingFlowcharts = set()\n",
    "\n",
    "for lex in verb_clause:\n",
    "    if lex not in senses:\n",
    "        missingFlowcharts.add(lex)\n",
    "info('No flowchart for {} verbs, e.g. {}'.format(len(missingFlowcharts), ', '.join(sorted(missingFlowcharts)[0:10])))\n",
    "\n",
    "good = True\n",
    "for lex in senses:\n",
    "    if lex not in verb_clause:\n",
    "        error('No verb {} in enriched corpus'.format(lex))\n",
    "        good = False\n",
    "if good:\n",
    "    info('All flowcharts belong to a verb in the corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21m 30s Applying the flowchart\n",
      "21m 43s Done\n",
      "21m 43s Computed 46969 clauses with flowchart\n"
     ]
    }
   ],
   "source": [
    "info('Applying the flowchart')\n",
    "\n",
    "outcome_lab = collections.Counter()\n",
    "outcome_lab_l = collections.defaultdict(lambda: collections.Counter())\n",
    "\n",
    "# we want an overview of the flowchart decisions per lexeme\n",
    "# Per lexeme, per sense_label we store the clauses\n",
    "\n",
    "decisions = collections.defaultdict(lambda: collections.defaultdict(dict))\n",
    "\n",
    "note_keyword_base = 'valence'\n",
    "\n",
    "nnotes = collections.Counter()\n",
    "\n",
    "ofs = open('{}/{}'.format(result_dir, 'valenceNotes.csv'), 'w')\n",
    "ofs.write('{}\\n'.format('\\t'.join(sfields)))\n",
    "\n",
    "for lex in verb_clause:\n",
    "    hasFlowchart = lex in senses\n",
    "    for (c,v) in verb_clause[lex]:\n",
    "        if F.vs.v(v) not in verbal_stems: continue\n",
    "    \n",
    "        book = F.book.v(L.u(v, 'book')[0])\n",
    "        chapter = F.chapter.v(L.u(v, 'chapter')[0])\n",
    "        verse = F.verse.v(L.u(v, 'verse')[0])\n",
    "        sentence_n = F.number.v(L.u(v, 'sentence')[0])\n",
    "        clause_n = F.number.v(c)\n",
    "        clause_atom_n = F.number.v(L.u(v, 'clause_atom')[0])\n",
    "        \n",
    "        verb = [L.u(v, 'phrase')[0]]\n",
    "        consts = constituents[c]\n",
    "        n_ = collections.defaultdict(lambda: 0)\n",
    "        for ckind in ckinds: n_[ckind] = len(consts[ckind])\n",
    "        \n",
    "        (sense_label, sense, status, constsRep) = flowchart(v, lex, verb, consts)\n",
    "        senseRep = 'legend' if sense == None else sense\n",
    "        senseDoc = 'Legend' if sense == None else 'FC_{}'.format(sense.replace('>', 'A').replace('<', 'O'))\n",
    "        senseLink = '{}/{}'.format(flowchartBase, senseDoc)\n",
    "        \n",
    "        constElems = []\n",
    "        for (constKind, constKindName) in constKinds.items():\n",
    "            if constKind not in constsRep: continue\n",
    "            material = constsRep[constKind]\n",
    "            if not material: continue\n",
    "            constElems.append('{}={}'.format(constKindName, material))\n",
    "\n",
    "        outcome_lab[sense_label] += 1\n",
    "        outcome_lab_l[lex][sense_label] += 1\n",
    "        decisions[lex][sense_label][c] = sense_label\n",
    "\n",
    "        ofs.write(sfields_fmt.format(\n",
    "            version,\n",
    "            book,\n",
    "            chapter,\n",
    "            verse,\n",
    "            clause_atom_n,\n",
    "            'T',\n",
    "            '',\n",
    "            status,\n",
    "            note_keyword_base,\n",
    "            'verb [{nm}|{vb}] has sense {sl} [{sn}]({slink}) {cs}'.format(\n",
    "                nm=F.number.v(L.u(v, 'phrase')[0]),\n",
    "                vb=F.g_word_utf8.v(v),\n",
    "                sn=senseRep,\n",
    "                slink=senseLink,\n",
    "                sl=sense_label,\n",
    "                cs='; '.join(constElems)\n",
    "            ),\n",
    "        ))\n",
    "        nnotes[note_keyword_base] += 1\n",
    "            \n",
    "ofs.close()\n",
    "info('Done')\n",
    "\n",
    "show_limit = 20\n",
    "for lex in debug_messages:\n",
    "    error(lex, tm=False)\n",
    "    for kind in debug_messages[lex]:\n",
    "        error('\\t{}'.format(kind), tm=False)\n",
    "        messages = debug_messages[lex][kind]\n",
    "        lm = len(messages)\n",
    "        error('\\t\\t{}{}'.format(\n",
    "            '\\n\\t\\t'.join(messages[0:show_limit]),\n",
    "            '' if lm <= show_limit else '\\n\\t\\tAND {} more'.format(lm-show_limit),\n",
    "        ), tm=False)\n",
    "\n",
    "info('Computed {} clauses with flowchart'.format(nnotes[note_keyword_base], tm=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3m 44s Reporting flowchart application\n",
      "valence    notes: 46969\n",
      "Total      notes: 46969\n",
      "All lexemes\n",
      "     Sense    --     : 17855 clauses\n",
      "     Sense    -i     :  3611 clauses\n",
      "     Sense    -b     :    70 clauses\n",
      "     Sense    -p     :  6528 clauses\n",
      "     Sense    -c     :  3206 clauses\n",
      "     Sense    d-     :  9926 clauses\n",
      "     Sense    di     :   846 clauses\n",
      "     Sense    db     :    56 clauses\n",
      "     Sense    dp     :  1846 clauses\n",
      "     Sense    dc     :   997 clauses\n",
      "     Sense    n.     :   511 clauses\n",
      "     Sense    l.     :   780 clauses\n",
      "     Sense    k.     :    53 clauses\n",
      "     Sense    i.     :   613 clauses\n",
      "     Sense    c.     :    71 clauses\n",
      "     All senses      : 46969 clauses\n",
      " \n",
      "<FH\n",
      "     Sense    --     :   727 clauses\n",
      "     Sense    -i     :   135 clauses\n",
      "     Sense    -b     :     3 clauses\n",
      "     Sense    -p     :    77 clauses\n",
      "     Sense    -c     :    32 clauses\n",
      "     Sense    d-     :   907 clauses\n",
      "     Sense    di     :    90 clauses\n",
      "     Sense    db     :     6 clauses\n",
      "     Sense    dp     :    70 clauses\n",
      "     Sense    dc     :    37 clauses\n",
      "     Sense    n.     :   110 clauses\n",
      "     Sense    l.     :    52 clauses\n",
      "     Sense    k.     :     5 clauses\n",
      "     Sense    i.     :    40 clauses\n",
      "     Sense    c.     :     3 clauses\n",
      "     All senses      :  2294 clauses\n",
      " \n",
      "BR>\n",
      "     Sense    --     :     4 clauses\n",
      "     Sense    -i     :     0 clauses\n",
      "     Sense    -b     :     0 clauses\n",
      "     Sense    -p     :     0 clauses\n",
      "     Sense    -c     :     0 clauses\n",
      "     Sense    d-     :    25 clauses\n",
      "     Sense    di     :     0 clauses\n",
      "     Sense    db     :     0 clauses\n",
      "     Sense    dp     :     2 clauses\n",
      "     Sense    dc     :     0 clauses\n",
      "     Sense    n.     :     2 clauses\n",
      "     Sense    l.     :     0 clauses\n",
      "     Sense    k.     :     0 clauses\n",
      "     Sense    i.     :     1 clauses\n",
      "     Sense    c.     :     0 clauses\n",
      "     All senses      :    34 clauses\n",
      " \n",
      "CJT\n",
      "     Sense    --     :     3 clauses\n",
      "     Sense    -i     :     1 clauses\n",
      "     Sense    -b     :     0 clauses\n",
      "     Sense    -p     :     2 clauses\n",
      "     Sense    -c     :     8 clauses\n",
      "     Sense    d-     :     7 clauses\n",
      "     Sense    di     :     3 clauses\n",
      "     Sense    db     :     1 clauses\n",
      "     Sense    dp     :    19 clauses\n",
      "     Sense    dc     :     9 clauses\n",
      "     Sense    n.     :    12 clauses\n",
      "     Sense    l.     :     8 clauses\n",
      "     Sense    k.     :     5 clauses\n",
      "     Sense    i.     :     3 clauses\n",
      "     Sense    c.     :     0 clauses\n",
      "     All senses      :    81 clauses\n",
      " \n",
      "DBQ\n",
      "     Sense    --     :     6 clauses\n",
      "     Sense    -i     :     0 clauses\n",
      "     Sense    -b     :     0 clauses\n",
      "     Sense    -p     :    26 clauses\n",
      "     Sense    -c     :     4 clauses\n",
      "     Sense    d-     :     1 clauses\n",
      "     Sense    di     :     0 clauses\n",
      "     Sense    db     :     0 clauses\n",
      "     Sense    dp     :     1 clauses\n",
      "     Sense    dc     :     1 clauses\n",
      "     Sense    n.     :     0 clauses\n",
      "     Sense    l.     :     0 clauses\n",
      "     Sense    k.     :     0 clauses\n",
      "     Sense    i.     :     0 clauses\n",
      "     Sense    c.     :     0 clauses\n",
      "     All senses      :    39 clauses\n",
      " \n",
      "FJM\n",
      "     Sense    --     :    11 clauses\n",
      "     Sense    -i     :     5 clauses\n",
      "     Sense    -b     :     2 clauses\n",
      "     Sense    -p     :    33 clauses\n",
      "     Sense    -c     :    32 clauses\n",
      "     Sense    d-     :    36 clauses\n",
      "     Sense    di     :    24 clauses\n",
      "     Sense    db     :     3 clauses\n",
      "     Sense    dp     :   148 clauses\n",
      "     Sense    dc     :    89 clauses\n",
      "     Sense    n.     :    53 clauses\n",
      "     Sense    l.     :    69 clauses\n",
      "     Sense    k.     :    19 clauses\n",
      "     Sense    i.     :    22 clauses\n",
      "     Sense    c.     :     3 clauses\n",
      "     All senses      :   549 clauses\n",
      " \n",
      "NTN\n",
      "     Sense    --     :   133 clauses\n",
      "     Sense    -i     :   151 clauses\n",
      "     Sense    -b     :     2 clauses\n",
      "     Sense    -p     :    69 clauses\n",
      "     Sense    -c     :    50 clauses\n",
      "     Sense    d-     :   186 clauses\n",
      "     Sense    di     :   295 clauses\n",
      "     Sense    db     :     1 clauses\n",
      "     Sense    dp     :   342 clauses\n",
      "     Sense    dc     :   124 clauses\n",
      "     Sense    n.     :    94 clauses\n",
      "     Sense    l.     :   310 clauses\n",
      "     Sense    k.     :    18 clauses\n",
      "     Sense    i.     :    88 clauses\n",
      "     Sense    c.     :     6 clauses\n",
      "     All senses      :  1869 clauses\n",
      " \n",
      "QR>\n",
      "     Sense    --     :   150 clauses\n",
      "     Sense    -i     :   108 clauses\n",
      "     Sense    -b     :     0 clauses\n",
      "     Sense    -p     :    65 clauses\n",
      "     Sense    -c     :    22 clauses\n",
      "     Sense    d-     :   102 clauses\n",
      "     Sense    di     :    35 clauses\n",
      "     Sense    db     :     0 clauses\n",
      "     Sense    dp     :    24 clauses\n",
      "     Sense    dc     :     7 clauses\n",
      "     Sense    n.     :    98 clauses\n",
      "     Sense    l.     :    29 clauses\n",
      "     Sense    k.     :     1 clauses\n",
      "     Sense    i.     :     8 clauses\n",
      "     Sense    c.     :     0 clauses\n",
      "     All senses      :   649 clauses\n",
      " \n",
      "ZQN\n",
      "     Sense    --     :    22 clauses\n",
      "     Sense    -i     :     0 clauses\n",
      "     Sense    -b     :     0 clauses\n",
      "     Sense    -p     :     0 clauses\n",
      "     Sense    -c     :     0 clauses\n",
      "     Sense    d-     :     0 clauses\n",
      "     Sense    di     :     0 clauses\n",
      "     Sense    db     :     0 clauses\n",
      "     Sense    dp     :     0 clauses\n",
      "     Sense    dc     :     0 clauses\n",
      "     Sense    n.     :     0 clauses\n",
      "     Sense    l.     :     0 clauses\n",
      "     Sense    k.     :     0 clauses\n",
      "     Sense    i.     :     0 clauses\n",
      "     Sense    c.     :     0 clauses\n",
      "     All senses      :    22 clauses\n",
      " \n"
     ]
    }
   ],
   "source": [
    "info('Reporting flowchart application')\n",
    "ntot = 0\n",
    "for (lab, n) in sorted(nnotes.items(), key=lambda x: x[0]):\n",
    "    ntot += n\n",
    "    print('{:<10} notes: {}'.format(lab, n))\n",
    "print('{:<10} notes: {}'.format('Total', ntot))\n",
    "\n",
    "for lex in [''] + sorted(senses):\n",
    "    print('All lexemes' if lex == '' else lex)\n",
    "    src_lab = outcome_lab if lex == '' else outcome_lab_l.get(lex, collections.defaultdict(lambda: 0))\n",
    "    tot = 0\n",
    "    for x in senseLabels:\n",
    "        n = src_lab[x]\n",
    "        tot += n\n",
    "        print('     Sense    {:<7}: {:>5} clauses'.format(x, n))\n",
    "    print('     All senses      : {:>5} clauses'.format(tot))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_decision(verbs=None, labels=None, books=None): # show all clauses that have a verb in verbs and a sense label in labels\n",
    "    results = []\n",
    "    for verb in decisions:\n",
    "        if verbs != None and verb not in verbs: continue\n",
    "        for label in decisions[verb]:\n",
    "            if labels != None and label not in labels: continue\n",
    "            for (c, stxt) in sorted(decisions[verb][label].items()):\n",
    "                book = T.sectionFromNode(L.u(c, 'book')[0])[0]\n",
    "                if books != None and book not in books: continue\n",
    "                sentence_words = L.d(L.u(c, 'sentence')[0], 'word')\n",
    "                results.append('{:<7} {:<12} {:<5} {:<2} {}\\n\\t{}\\n\\t{}\\n'.format(\n",
    "                    c,\n",
    "                    '{} {}: {}'.format(*T.sectionFromNode(c)),\n",
    "                    verb,\n",
    "                    label,\n",
    "                    stxt,\n",
    "                    T.text(sentence_words, fmt='text-trans-plain'),\n",
    "                    ' '.join(F.gloss.v(w) for w in sentence_words),\n",
    "                ).replace('<', '&lt;'))\n",
    "    print('\\n'.join(sorted(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467293  Isaiah 3: 7  FJM   n. n.\n",
      "\tL> TFJMNJ QYJN &lt;M \n",
      "\tnot put chief people\n",
      "\n",
      "467456  Isaiah 5: 20 FJM   l. l.\n",
      "\tHWJ H >MRJM L  R&lt; W L  VWB FMJM XCK L >WR W >WR L XCK FMJM MR L MTWQ W MTWQ L MR \n",
      "\talas the say to the evil and to the good put darkness to light and light to darkness put bitter to sweet and sweet to bitter\n",
      "\n",
      "467458  Isaiah 5: 20 FJM   l. l.\n",
      "\tHWJ H >MRJM L  R&lt; W L  VWB FMJM XCK L >WR W >WR L XCK FMJM MR L MTWQ W MTWQ L MR \n",
      "\talas the say to the evil and to the good put darkness to light and light to darkness put bitter to sweet and sweet to bitter\n",
      "\n",
      "467855  Isaiah 10: 6 FJM   n. n.\n",
      "\tW &lt;L &lt;M &lt;BRTJ >YWNW L CLL CLL W L BZ BZ W L FJMW MRMS K XMR XWYWT \n",
      "\tand upon people anger command to plunder plunder and to spoil spoiling and to put trampled land as clay outside\n",
      "\n",
      "468059  Isaiah 13: 9 FJM   l. l.\n",
      "\tHNH JWM JHWH B> >KZRJ W &lt;BRH W XRWN >P L FWM H >RY L CMH \n",
      "\tbehold day YHWH come cruel and anger and anger nose to put the earth to destruction\n",
      "\n",
      "468161  Isaiah 14: 17 FJM   k. k.\n",
      "\tFM TBL K  MDBR \n",
      "\tput world as the desert\n",
      "\n",
      "468182  Isaiah 14: 23 FJM   l. l.\n",
      "\tW FMTJH L MWRC QPD W >GMJ MJM \n",
      "\tand put to possession hedgehog and reedy pool water\n",
      "\n",
      "468546  Isaiah 21: 4 FJM   l. l.\n",
      "\t>T NCP XCQJ FM LJ L XRDH \n",
      "\t&lt;object marker> breeze desire put to to trembling\n",
      "\n",
      "468747  Isaiah 23: 13 FJM   l. l.\n",
      "\tFMH L MPLH \n",
      "\tput to decay\n",
      "\n",
      "468867  Isaiah 25: 2 FJM   l. l.\n",
      "\tKJ FMT M &lt;JR L  GL QRJH BYWRH L MPLH >RMWN ZRJM M &lt;JR \n",
      "\tthat put from town to the heap town fortified to decay dwelling tower strange from town\n",
      "\n",
      "469020  Isaiah 27: 9 FJM   k. k.\n",
      "\tB FWMW KL >BNJ MZBX K >BNJ GR MNPYWT L> JQMW >CRJM W XMNJM \n",
      "\tin put whole stone altar as stone chalk shatter not arise asherah and incense-stand\n",
      "\n",
      "469107  Isaiah 28: 15 FJM   n. n.\n",
      "\tKJ FMNW KZB MXSNW \n",
      "\tthat put lie refuge\n",
      "\n",
      "469113  Isaiah 28: 17 FJM   l. l.\n",
      "\tW FMTJ MCPV L QW W YDQH L MCQLT \n",
      "\tand put justice to line and justice to leveller\n",
      "\n",
      "469152  Isaiah 28: 25 FJM   n. n.\n",
      "\tW FM XVH FWRH W F&lt;RH NSMN W KSMT GBLTW \n",
      "\tand put wheat &lt;animal> and barley &lt;uncertain> and spelt boundary\n",
      "\n",
      "469975  Isaiah 37: 29 FJM   dp dp\n",
      "\tW FMTJ XXJ B >PK W MTGJ B FPTJK \n",
      "\tand put thorn in nose and bridle in lip\n",
      "\n",
      "470345  Isaiah 41: 15 FJM   l. l.\n",
      "\tHNH FMTJK L MWRG XRWY XDC B&lt;L PJPJWT \n",
      "\tbehold put to threshing-sledge threshing instrument new lord, baal double-edged\n",
      "\n",
      "470348  Isaiah 41: 15 FJM   k. k.\n",
      "\tW GB&lt;WT K  MY TFJM \n",
      "\tand hill as the chaff put\n",
      "\n",
      "470363  Isaiah 41: 18 FJM   l. l.\n",
      "\t>FJM MDBR L >GM MJM W >RY YJH L MWY>J MJM \n",
      "\tput desert to reedy pool water and earth dry country to issue water\n",
      "\n",
      "470366  Isaiah 41: 19 FJM   dp dp\n",
      "\t>FJM B  &lt;RBH BRWC TDHR W T>CWR JXDW \n",
      "\tput in the desert juniper box tree and cypress together\n",
      "\n",
      "470369  Isaiah 41: 20 FJM   -- --\n",
      "\tW JFJMW \n",
      "\tand put\n",
      "\n",
      "470383  Isaiah 41: 22 FJM   d- d-\n",
      "\tW NFJMH LBNW \n",
      "\tand put heart\n",
      "\n",
      "470440  Isaiah 42: 4 FJM   dp dp\n",
      "\t&lt;D JFJM B  >RY MCPV \n",
      "\tunto put in the earth justice\n",
      "\n",
      "470473  Isaiah 42: 12 FJM   l. l.\n",
      "\tJFJMW L JHWH KBWD \n",
      "\tput to YHWH weight\n",
      "\n",
      "470488  Isaiah 42: 15 FJM   l. l.\n",
      "\tW FMTJ NHRWT L  >JJM \n",
      "\tand put stream to the coast, island\n",
      "\n",
      "470544  Isaiah 42: 25 FJM   -c -c\n",
      "\tW L> JFJM &lt;L LB \n",
      "\tand not put upon heart\n",
      "\n",
      "470636  Isaiah 43: 19 FJM   dp dp\n",
      "\t>P >FJM B  MDBR DRK B JCMWN NHRWT \n",
      "\teven put in the desert way in wilderness stream\n",
      "\n",
      "470697  Isaiah 44: 7 FJM   d- d-\n",
      "\tW J&lt;RKH LJ M FWMJ &lt;M &lt;WLM \n",
      "\tand arrange to from put people eternity\n",
      "\n",
      "471069  Isaiah 47: 6 FJM   di di\n",
      "\tL> FMT LHM RXMJM \n",
      "\tnot put to compassion\n",
      "\n",
      "471073  Isaiah 47: 7 FJM   dc dc\n",
      "\t&lt;D L> FMT >LH &lt;L LBK \n",
      "\tunto not put these upon heart\n",
      "\n",
      "471243  Isaiah 49: 2 FJM   k. k.\n",
      "\tW JFM PJ K XRB XDH \n",
      "\tand put mouth as dagger sharp\n",
      "\n",
      "471245  Isaiah 49: 2 FJM   l. l.\n",
      "\tW JFJMNJ L XY BRWR \n",
      "\tand put to arrow purge\n",
      "\n",
      "471296  Isaiah 49: 11 FJM   l. l.\n",
      "\tW FMTJ KL HRJ L  DRK \n",
      "\tand put whole mountain to the way\n",
      "\n",
      "471384  Isaiah 50: 2 FJM   n. n.\n",
      "\t>FJM NHRWT MDBR \n",
      "\tput stream desert\n",
      "\n",
      "471388  Isaiah 50: 3 FJM   n. n.\n",
      "\tW FQ >FJM KSWTM \n",
      "\tand sack put covering\n",
      "\n",
      "471403  Isaiah 50: 7 FJM   k. k.\n",
      "\t&lt;L KN FMTJ PNJ K  XLMJC \n",
      "\tupon thus put face as the flint\n",
      "\n",
      "471445  Isaiah 51: 3 FJM   k. k.\n",
      "\tW JFM MDBRH K &lt;DN W &lt;RBTH K GN JHWH \n",
      "\tand put desert as Eden and desert as garden YHWH\n",
      "\n",
      "471486  Isaiah 51: 10 FJM   n. n.\n",
      "\tH LW> >T HJ> H MXRBT JM MJ THWM RBH H FMH M&lt;MQJ JM DRK L &lt;BR G>WLJM \n",
      "\t&lt;interrogative> not you she the be dry sea water primeval ocean much the put depths sea way to pass redeem\n",
      "\n",
      "471516  Isaiah 51: 16 FJM   dp dp\n",
      "\tW >FJM DBRJ B PJK \n",
      "\tand put word in mouth\n",
      "\n",
      "471552  Isaiah 51: 23 FJM   dp dp\n",
      "\tW FMTJH B JD MWGJK >CR >MRW L NPCK \n",
      "\tand put in hand grieve &lt;relative> say to soul\n",
      "\n",
      "471556  Isaiah 51: 23 FJM   k. k.\n",
      "\tW TFJMJ K  >RY GWK W K  XWY L  &lt;BRJM \n",
      "\tand put as the earth back and as the outside to the pass\n",
      "\n",
      "471743  Isaiah 54: 12 FJM   n. n.\n",
      "\tW FMTJ KDKD CMCTJK W C&lt;RJK L >BNJ >QDX W KL GBWLK L >BNJ XPY \n",
      "\tand put ruby sun and gate to stone beryl and whole boundary to stone pleasure\n",
      "\n",
      "471906  Isaiah 57: 1 FJM   -c -c\n",
      "\tW >JN >JC FM &lt;L LB \n",
      "\tand &lt;NEG> man put upon heart\n",
      "\n",
      "471929  Isaiah 57: 7 FJM   dp dp\n",
      "\t&lt;L HR GBH W NF> FMT MCKBK \n",
      "\tupon mountain high and lift put couch\n",
      "\n",
      "471932  Isaiah 57: 8 FJM   dp dp\n",
      "\tW >XR H DLT W H MZWZH FMT ZKRWNK \n",
      "\tand after the door and the door-post put remembrance\n",
      "\n",
      "471952  Isaiah 57: 11 FJM   -c -c\n",
      "\tL> FMT &lt;L LBK \n",
      "\tnot put upon heart\n",
      "\n",
      "472184  Isaiah 59: 21 FJM   -p -p\n",
      "\tRWXJ >CR &lt;LJK W DBRJ >CR FMTJ B PJK L> JMWCW M PJK W M PJ ZR&lt;K W M PJ ZR&lt; ZR&lt;K M &lt;TH W &lt;D &lt;WLM \n",
      "\twind &lt;relative> upon and word &lt;relative> put in mouth not depart from mouth and from mouth seed and from mouth seed seed from now and unto eternity\n",
      "\n",
      "472244  Isaiah 60: 15 FJM   l. l.\n",
      "\tTXT HJWTK &lt;ZWBH W FNW>H W >JN &lt;WBR W FMTJK L G>WN &lt;WLM MFWF DWR W DWR \n",
      "\tunder part be leave and hate and &lt;NEG> pass and put to height eternity joy generation and generation\n",
      "\n",
      "472253  Isaiah 60: 17 FJM   n. n.\n",
      "\tW FMTJ PQDTK CLWM W NGFJK YDQH \n",
      "\tand put commission peace and drive justice\n",
      "\n",
      "472285  Isaiah 61: 3 FJM   -- --\n",
      "\tCLXNJ L XBC L NCBRJ LB L QR> L CBWJM DRWR W L >SWRJM PQX_QWX L QR> CNT RYWN L JHWH W JWM NQM L >LHJNW L NXM KL >BLJM L FWM L >BLJ YJWN L TT LHM P>R TXT >PR CMN FFWN TXT >BL M&lt;VH THLH TXT RWX KHH \n",
      "\tsend to saddle to break heart to call to take captive release and to bind opening to call year pleasure to YHWH and day vengeance to god(s) to repent, console whole mourning to put to mourning Zion to give to headdress under part dust oil rejoicing under part mourning rites wrap praise under part wind dim\n",
      "\n",
      "472357  Isaiah 62: 7 FJM   n. n.\n",
      "\tW &lt;D JFJM >T JRWCLM THLH B  >RY \n",
      "\tand unto put &lt;object marker> Jerusalem praise in the earth\n",
      "\n",
      "472436  Isaiah 63: 11 FJM   dp dp\n",
      "\t>JH H FM B QRBW >T RWX QDCW MWLJK L JMJN MCH ZRW&lt; TP>RTW BWQ&lt; MJM M PNJHM L &lt;FWT LW CM &lt;WLM MWLJKM B  THMWT \n",
      "\twhere the put in interior &lt;object marker> wind holiness walk to right-hand side Moses arm splendour split water from face to make to name eternity walk in the primeval ocean\n",
      "\n",
      "472738  Isaiah 66: 19 FJM   dp dp\n",
      "\tW FMTJ BHM >WT \n",
      "\tand put in sign\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_decision(verbs={'FJM'}, books={'Isaiah'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
